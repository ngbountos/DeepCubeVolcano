{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SimCLR Code based on https://github.com/sthalles/SimCLR/blob/master/simclr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-capacity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T08:50:12.203802Z",
     "start_time": "2021-05-31T08:50:11.336053Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def save_config_file(model_checkpoints_folder, args):\n",
    "    if not os.path.exists(model_checkpoints_folder):\n",
    "        os.makedirs(model_checkpoints_folder)\n",
    "        with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:\n",
    "            yaml.dump(args, outfile, default_flow_style=False)\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-upset",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T08:51:44.215022Z",
     "start_time": "2021-05-31T08:51:44.196058Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "class SimCLR(object):\n",
    "\n",
    "    def __init__(self,train_loader):\n",
    "        self.backbone = torchvision.models.resnet18(pretrained = True)\n",
    "        dim_mlp = self.backbone.fc.in_features\n",
    "        # add mlp projection head\n",
    "        self.backbone.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.backbone.fc)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.backbone.to(self.device)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=len(train_loader), eta_min=0,\n",
    "                                                           last_epoch=-1)\n",
    "        self.writer = SummaryWriter()\n",
    "        logging.basicConfig(filename=os.path.join(self.writer.log_dir, 'training.log'), level=logging.DEBUG)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.device)\n",
    "        #Should be the same with dataloaders batch size\n",
    "        self.batch_size = 112\n",
    "        self.n_views = 2\n",
    "        self.temperature = 0.5\n",
    "        self.epochs = 200\n",
    "    def info_nce_loss(self, features):\n",
    "\n",
    "        labels = torch.cat([torch.arange(self.batch_size) for i in range(self.n_views)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.device)\n",
    "\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "        \n",
    "\n",
    "        # discard the main diagonal from both: labels and similarities matrix\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        # select and combine multiple positives\n",
    "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "        # select only the negatives the negatives\n",
    "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.device)\n",
    "\n",
    "        logits = logits / self.temperature\n",
    "        return logits, labels\n",
    "\n",
    "    def train(self, train_loader):\n",
    "\n",
    "        scaler = GradScaler(enabled=False)\n",
    "\n",
    "        n_iter = 0\n",
    "        logging.info(f\"Start SimCLR training for {self.epochs} epochs.\")\n",
    "        logging.info(f\"Training with gpu: {False}.\")\n",
    "\n",
    "        for epoch_counter in range(self.epochs):\n",
    "            running_loss = 0\n",
    "            count = 0\n",
    "            for images, _ in tqdm(train_loader):\n",
    "                images = torch.cat(images, dim=0)\n",
    "\n",
    "                images = images.to(self.device)\n",
    "\n",
    "                with autocast(enabled=False):\n",
    "                    features = self.model(images)\n",
    "                    logits, labels = self.info_nce_loss(features)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "                    running_loss += loss.mean().item()\n",
    "                    count+=1\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                if n_iter % 20 ==0 :\n",
    "                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
    "                    print('Epoch : ',epoch_counter, ' Iter : ',n_iter)\n",
    "                    print('Loss : ',loss.mean().item())\n",
    "                    print('acc/top1 : ',top1[0].item())\n",
    "                    print('acc/top5 : ',top5[0].item())\n",
    "                    self.writer.add_scalar('loss', loss, global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top1', top1[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top5', top5[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('learning_rate', self.scheduler.get_lr()[0], global_step=n_iter)\n",
    "\n",
    "                n_iter += 1\n",
    "            print('Epoch ',epoch_counter,' loss :',running_loss/count)\n",
    "            # warmup for the first 10 epochs\n",
    "            if epoch_counter >= 10:\n",
    "                self.scheduler.step()\n",
    "            logging.debug(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n",
    "\n",
    "        logging.info(\"Training has finished.\")\n",
    "        # save model checkpoints\n",
    "        checkpoint_name = 'checkpoint_{:04d}.pth.tar'.format(self.epochs)\n",
    "        save_checkpoint({\n",
    "            'epoch': self.epochs,\n",
    "            'arch': 'ResNet18',\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }, is_best=False, filename=os.path.join(self.writer.log_dir, checkpoint_name))\n",
    "        logging.info(f\"Model checkpoint and metadata has been saved at {self.writer.log_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-technology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T08:52:00.317572Z",
     "start_time": "2021-05-31T08:52:00.268093Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as A\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset='../Data/Dataset', setting='train', gray=False,day = False, sim = True, original = False):\n",
    "        self.path = dataset\n",
    "        self.classes = os.listdir(self.path)\n",
    "        self.day = day\n",
    "        self.interferograms = []\n",
    "        self.interferograms_normal = []\n",
    "        self.interferograms_deformation = []\n",
    "        self.ones_days = []\n",
    "        self.zero_days = []\n",
    "        self.sim = sim\n",
    "        self.original = original\n",
    "        for data_class in self.classes:\n",
    "            images = os.listdir(self.path + '/' + data_class)\n",
    "            for image in images:\n",
    "                \n",
    "                days = 0\n",
    "                image_dict = {'path': self.path + '/' + data_class + '/' + image, 'label': data_class, 'days':days}\n",
    "                self.interferograms.append(image_dict)\n",
    "                if int(data_class)==0:\n",
    "                    self.zero_days.append(days)\n",
    "                    self.interferograms_normal.append(image_dict)\n",
    "                else:\n",
    "                    self.interferograms_deformation.append(image_dict)\n",
    "                    self.ones_days.append(days)\n",
    "        \n",
    "        self.num_examples = len(self.interferograms)\n",
    "        self.set = setting\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_examples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.set == 'train' and self.sim==False:\n",
    "          choice = random.randint(0,10)\n",
    "\n",
    "          if choice %2 != 0:\n",
    "              choice_normal = random.randint(0,len(self.interferograms_normal)-1)\n",
    "              image_data = self.interferograms_normal[choice_normal]\n",
    "          else:\n",
    "              choice_deform = random.randint(0,len(self.interferograms_deformation)-1)\n",
    "              image_data = self.interferograms_deformation[choice_deform]\n",
    "        else:\n",
    "          image_data = self.interferograms[index]\n",
    "        image_file = image_data['path']\n",
    "        image_label = image_data['label']\n",
    "        image = cv.imread(image_file)\n",
    "        zero = np.zeros_like(image)\n",
    "        if image is None:\n",
    "            print(image_file)    \n",
    "        gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        original = image\n",
    "        original = original[:224,:224,:]\n",
    "        zero[:,:,0] = gray\n",
    "        zero[:,:,1] = gray\n",
    "        zero[:,:,2 ] = gray\n",
    "        image = zero\n",
    "        image = image[:224, :224, :]\n",
    "        if self.set == 'none':\n",
    "            angle = random.randint(0, 360)\n",
    "\n",
    "            M = cv.getRotationMatrix2D((113, 113), angle, 1)\n",
    "            image = cv.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "        if self.set == 'train':\n",
    "          transform = A.Compose([\n",
    "                A.augmentations.transforms.HorizontalFlip(p=0.8),\n",
    "                A.augmentations.transforms.VerticalFlip(p=0.8),\n",
    "                A.augmentations.transforms.ElasticTransform(p=0.8),\n",
    "                A.augmentations.transforms.Cutout(p=0.8),\n",
    "                A.augmentations.transforms.MultiplicativeNoise(p=0.8),\n",
    "                A.augmentations.transforms.GaussianBlur(p=0.8),\n",
    "                A.augmentations.transforms.GaussNoise(p=0.8)\n",
    "            ])\n",
    "          transformed = transform(image= image)\n",
    "          augmented = transformed['image']\n",
    "          \n",
    "          sim = self.sim  \n",
    "          if sim == True:\n",
    "              transform2 = A.Compose([\n",
    "                    A.augmentations.transforms.HorizontalFlip(p=0.8),\n",
    "                    A.augmentations.transforms.VerticalFlip(p=0.8),\n",
    "                    A.augmentations.transforms.ElasticTransform(p=0.8),\n",
    "                    A.augmentations.transforms.Cutout(p=0.8),\n",
    "                    A.augmentations.transforms.MultiplicativeNoise(p=0.8),\n",
    "                    A.augmentations.transforms.GaussianBlur(p=0.8),\n",
    "                    A.augmentations.transforms.GaussNoise(p=0.8)\n",
    "                ])\n",
    "              transformed2 = transform2(image=image)\n",
    "              image = transformed2['image']\n",
    "              flag = True\n",
    "          \n",
    "        else:\n",
    "          \n",
    "          augmented = None\n",
    "          \n",
    "          flag = False\n",
    " \n",
    "        image = torch.from_numpy(image).float().permute(2,0,1)\n",
    "        original = torch.from_numpy(original).float().permute(2,0,1)\n",
    "        \n",
    "        image = torchvision.transforms.Normalize((127.0710,127.0710,127.0710), (71.4902,71.4902,71.4902))(image)\n",
    "        if augmented is None:\n",
    "            augmented = torch.tensor(int(image_label))\n",
    "        else:\n",
    "            augmented = torch.from_numpy(augmented).float().permute(2,0,1)\n",
    "            #merged\n",
    "            augmented = torchvision.transforms.Normalize((127.0710,127.0710,127.0710), (71.4902,71.4902,71.4902))(augmented)\n",
    "            \n",
    "        if image.shape[1]<224 or image.shape[2]<224:\n",
    "            print(image_file)\n",
    "        if self.original:\n",
    "            return (image,augmented,original),int(image_label), image_file\n",
    "        return (image, augmented), int(image_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-worcester",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T08:52:02.998821Z",
     "start_time": "2021-05-31T08:52:02.996575Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = 'S1/Train'\n",
    "test_dir = 'S1/Test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-equality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T09:55:14.907508Z",
     "start_time": "2021-05-31T09:55:14.887966Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.optim as optim\n",
    "#For SimcLR Training sim = True. For finetuning sim = False\n",
    "train_dataset = Dataset(data_dir,setting='train',sim=True)\n",
    "val_dataset =  Dataset(test_dir,setting='test',original=False)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=112, shuffle=True, num_workers=1, drop_last = True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(val_dataset, batch_size=112, shuffle=True, num_workers=1, drop_last = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-butter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T09:26:03.335959Z",
     "start_time": "2021-05-31T09:11:36.814792Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "simclr = SimCLR(train_loader)\n",
    "simclr.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-prison",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T09:26:03.384649Z",
     "start_time": "2021-05-31T09:26:03.340690Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(simclr.model.state_dict(), 'ModelSimclr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-samuel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T20:14:03.829453Z",
     "start_time": "2021-04-14T20:14:03.825236Z"
    }
   },
   "outputs": [],
   "source": [
    "print(simclr.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-noise",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T09:55:30.022940Z",
     "start_time": "2021-05-31T09:55:30.007461Z"
    }
   },
   "outputs": [],
   "source": [
    "#For SimcLR Training sim = True. For finetuning sim = False\n",
    "train_dataset = Dataset(data_dir,setting='train',sim=False)\n",
    "val_dataset =  Dataset(test_dir,setting='test',original=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-complex",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T15:51:22.142485Z",
     "start_time": "2021-04-28T15:51:22.126259Z"
    }
   },
   "source": [
    "uniqueDataset = Dataset('ClearDataset/Train', setting='train')\n",
    "uniqueloader = torch.utils.data.DataLoader(uniqueDataset, batch_size=1, shuffle=False, num_workers=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-michigan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T10:02:46.126036Z",
     "start_time": "2021-05-31T09:55:34.328600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(999)\n",
    "\n",
    "simclr = SimCLR(train_loader)\n",
    "model_path = 'ModelSimclr.pt'#'YOUR_MODEL_PATH' \n",
    "simclr.model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "simclr.model.fc = nn.Identity()\n",
    "for param in simclr.model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "model = simclr.model\n",
    "\n",
    "model.fc = nn.Linear(512,2)\n",
    "\n",
    "model.to(simclr.device)\n",
    "print(simclr.device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.1)\n",
    "\n",
    "device = simclr.device\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, ((inputs,_), labels) in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 20 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "            print('Accuracy of the network on the trainin images: %d %%' % (\n",
    "            100 * correct / total))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    scheduler.step()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            (images,_), labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            print('Labels')\n",
    "            print(labels)\n",
    "            print('Predicted')\n",
    "            print(predicted)\n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-longitude",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T08:42:52.063290Z",
     "start_time": "2021-04-05T08:42:50.559029Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --user torchcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-responsibility",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T09:52:50.775579Z",
     "start_time": "2021-05-31T09:52:50.567450Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cam(file_path):\n",
    "  model.to('cpu')\n",
    "  import math\n",
    "  from torchvision.transforms.functional import to_pil_image\n",
    "  from torchcam.utils import overlay_mask\n",
    "\n",
    "  gradcam = True\n",
    "  if gradcam:\n",
    "\n",
    "      from torchcam.cams import SmoothGradCAMpp, CAM, GradCAM, ScoreCAM, GradCAMpp, SSCAM, ISCAM\n",
    "      image = cv.imread(file_path)\n",
    "      zero = np.zeros_like(image)\n",
    "      gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "      zero[:,:,0] = gray\n",
    "      zero[:,:,1] = gray\n",
    "      zero[:,:,2 ] = gray\n",
    "      image = zero\n",
    "\n",
    "      img =  image \n",
    "      img = img[:224,:224,:]\n",
    "      pil_img = Image.fromarray(img)\n",
    "\n",
    "      img = torch.from_numpy(img).float().permute(2,0,1).unsqueeze(dim=0)\n",
    "      print(img.shape)\n",
    "      img_tensor = torchvision.transforms.Normalize((127.0710,127.0710,127.0710), (71.4902,71.4902,71.4902))(img)\n",
    "\n",
    "      # Hook the corresponding layer in the model\n",
    "      cam_extractors = [\n",
    "          CAM(model,fc_layer='fc'),\n",
    "         \n",
    "      ]\n",
    "\n",
    "      # Don't trigger all hooks\n",
    "      for extractor in cam_extractors:\n",
    "          extractor._hooks_enabled = False\n",
    "\n",
    "      num_rows = 2\n",
    "      num_cols = math.ceil(len(cam_extractors) / num_rows)\n",
    "      \n",
    "      class_idx = None\n",
    "      for idx, extractor in enumerate(cam_extractors):\n",
    "          extractor._hooks_enabled = True\n",
    "          model.zero_grad()\n",
    "          scores = model(img_tensor)\n",
    "\n",
    "          # Select the class index\n",
    "          class_idx = scores.squeeze(0).argmax().item() if class_idx is None else class_idx\n",
    "          print(class_idx)\n",
    "          # Use the hooked data to compute activation map\n",
    "          activation_map = extractor(class_idx, scores).cpu()\n",
    "\n",
    "          # Clean data\n",
    "          extractor.clear_hooks()\n",
    "          extractor._hooks_enabled = False\n",
    "          # Convert it to PIL image\n",
    "          # The indexing below means first image in batch\n",
    "          heatmap = to_pil_image(activation_map, mode='F')\n",
    "          # Plot the result\n",
    "          result = overlay_mask(pil_img, heatmap)\n",
    "          plt.imshow(result)\n",
    "          \n",
    "          plt.title(extractor.__class__.__name__)\n",
    "      \n",
    "      plt.tight_layout()\n",
    "      if True:\n",
    "          plt.savefig('result'+str(idx) ,dpi=200, transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "      plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-moderator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T10:23:59.135993Z",
     "start_time": "2021-05-31T10:23:59.130853Z"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluate\n",
    "test = Dataset('C1', setting='train',sim=False,original=True)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False, num_workers=1,drop_last=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-distributor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T09:53:00.533925Z",
     "start_time": "2021-05-31T09:53:00.531393Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-breath",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T10:24:29.123310Z",
     "start_time": "2021-05-31T10:24:04.489268Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib\n",
    "import kornia\n",
    "\n",
    "torch.manual_seed(999)\n",
    "\n",
    "verbose = False\n",
    "\n",
    "device = simclr.device\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "model.to(device)\n",
    "model.eval()\n",
    "false_positives = 0\n",
    "total_negatives = 0\n",
    "false_negatives = 0\n",
    "true_positives = 0 \n",
    "true_negatives = 0\n",
    "print(len(testloader.dataset))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(testloader):\n",
    "        (images,augm,original), labels, path = data\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        plt.tick_params(\n",
    "            axis='both',          # changes apply to the x-axis\n",
    "            #which='both',      # both major and minor ticks are affected\n",
    "            bottom=False,      # ticks along the bottom edge are off\n",
    "            top=False,         # ticks along the top edge are off\n",
    "            labelbottom=False,\n",
    "            labelleft=False,\n",
    "            left=False,\n",
    "            )\n",
    "        if verbose:\n",
    "            plt.imshow(images.cpu().detach().squeeze().numpy().transpose(1,2,0)/255)\n",
    "            score = nn.Softmax()(outputs).max().item()\n",
    "            \n",
    "            plt.show()\n",
    "            plt.tick_params(\n",
    "            axis='both',          # changes apply to the x-axis\n",
    "            #which='both',      # both major and minor ticks are affected\n",
    "            bottom=False,      # ticks along the bottom edge are off\n",
    "            top=False,         # ticks along the top edge are off\n",
    "            labelbottom=False,\n",
    "            labelleft=False,\n",
    "            left=False,\n",
    "            )\n",
    "            plt.imshow(augm.cpu().detach().squeeze().squeeze().numpy().transpose(1,2,0)/255)\n",
    "            plt.show()\n",
    "\n",
    "        total_negatives += (labels==0).sum().item()\n",
    "        false_positives += (predicted[labels==0] == 1).sum().item()\n",
    "        false_negatives += (predicted[labels==1] == 0).sum().item()\n",
    "        true_positives += (predicted[labels==1] == 1).sum().item()\n",
    "        true_negatives += (predicted[labels==0] == 0).sum().item()\n",
    "        \n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "print('Correct : ',correct)\n",
    "print('Total : ', total)\n",
    "print('False Positives : ',false_positives)\n",
    "print('True Positives: ', true_positives)\n",
    "print('False Negatives : ',false_negatives)\n",
    "print('True Negatives : ', true_negatives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-deployment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T22:40:05.170362Z",
     "start_time": "2021-05-09T22:40:03.527465Z"
    }
   },
   "source": [
    "# cam('test3Cropped/1/20210217_20210301.geo.diff.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-genome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T09:54:00.347601Z",
     "start_time": "2021-05-31T09:53:59.900874Z"
    }
   },
   "outputs": [],
   "source": [
    "cam('C1/1/iceland_d_20201020_20201119.geo.diff1_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-artist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
